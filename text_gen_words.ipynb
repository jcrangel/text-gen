{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_gen_words.ipynb","provenance":[{"file_id":"1psXBpbnXITE13Wkw6hnGVq_IYg1T2fmm","timestamp":1572910113905},{"file_id":"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_classification_rnn.ipynb","timestamp":1572035359340}],"collapsed_sections":[],"last_runtime":{"build_target":"//learning/brain/python/client:colab_notebook_py3","kind":"private"}},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hX4n9TsbGw-f"},"source":["##### Copyright 2018 The TensorFlow Authors."]},{"cell_type":"code","metadata":{"cellView":"form","colab_type":"code","id":"0nbI5DtDGw-i","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9TnJztDZGw-n"},"source":["# Text classification with an RNN"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AfN3bMR5Gw-o"},"source":["<table class=\"tfo-notebook-buttons\" align=\"left\">\n","  <td>\n","    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/text/text_classification_rnn\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/text/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n","  </td>\n","  <td>\n","    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n","  </td>\n","  <td>\n","    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/tutorials/text/text_classification_rnn.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n","  </td>\n","</table>"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"lUWearf0Gw-p"},"source":["This text classification tutorial trains a [recurrent neural network](https://developers.google.com/machine-learning/glossary/#recurrent_neural_network) on the [IMDB large movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/) for sentiment analysis."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_2VQo4bajwUU"},"source":["## Setup"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z682XYsrjkY9","colab":{}},"source":["from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow_datasets as tfds\n","import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"SHRwRoP2nVHX","colab":{}},"source":["dataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\n","                          as_supervised=True)\n","train_dataset, test_dataset = dataset['train'], dataset['test']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MCorLciXSDJE"},"source":[" The dataset `info` includes the encoder (a `tfds.features.text.SubwordTextEncoder`)."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EplYp5pNnW1S","colab":{}},"source":["encoder = info.features['text'].encoder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e7ACuHM5hFp3","colab":{}},"source":["print ('Vocabulary size: {}'.format(encoder.vocab_size))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"tAfGg8YRe6fu"},"source":["This text encoder will reversibly encode any string, falling back to byte-encoding if necessary."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Bq6xDmf2SAs-","colab":{}},"source":["sample_string = 'Hello TensorFlow.'\n","\n","encoded_string = encoder.encode(sample_string)\n","print ('Encoded string is {}'.format(encoded_string))\n","\n","original_string = encoder.decode(encoded_string)\n","print ('The original string: \"{}\"'.format(original_string))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TN7QbKaM4-5H","colab":{}},"source":["assert original_string == sample_string"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"MDVc6UGO5Dh6","colab":{}},"source":["for index in encoded_string:\n","  print ('{} ----> {}'.format(index, encoder.decode([index])))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GlYWqhTVlUyQ"},"source":["## Prepare the data for training"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"z2qVJzcEluH_"},"source":["Next create batches of these encoded strings. Use the `padded_batch` method to zero-pad the sequences to the length of the longest string n the batch:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"dDsCaZCDYZgm","colab":{}},"source":["BUFFER_SIZE = 10000\n","BATCH_SIZE = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VznrltNOnUc5","colab":{}},"source":["train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n","train_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\n","\n","test_dataset = test_dataset.padded_batch(BATCH_SIZE, test_dataset.output_shapes)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"A75VueVu5z-L","colab_type":"code","outputId":"b2afc018-11e9-401e-883c-e0be748b15d0","executionInfo":{"status":"ok","timestamp":1572916500139,"user_tz":360,"elapsed":1624,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":219}},"source":["for input_batch, target_batch in train_dataset.take(1):\n","  print(input_batch,'\\n')\n","  print(target_batch)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tf.Tensor(\n","[[  62    9    4 ...    0    0    0]\n"," [6110 7961 7418 ...    0    0    0]\n"," [  12   31    4 ...    0    0    0]\n"," ...\n"," [  62    9   33 ...    0    0    0]\n"," [ 750    8   91 ...    0    0    0]\n"," [7969   62    9 ...    0    0    0]], shape=(32, 1172), dtype=int64) \n","\n","tf.Tensor([1 0 0 1 1 0 1 1 0 0 1 0 0 1 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 1 1 0], shape=(32,), dtype=int64)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bjUqGVBxGw-t"},"source":["## Create the model"]},{"cell_type":"code","metadata":{"id":"AVdtum6S0aSG","colab_type":"code","colab":{}},"source":["# The embedding dimension\n","embedding_dim = 256\n","\n","# Number of RNN units\n","rnn_units = 1024\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7erqgi7x0HF4","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LwfoBkmRYcP3","colab":{}},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.GRU(rnn_units,\n","                        return_sequences=True,\n","                        stateful=True,\n","                        recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)\n","  ])\n","  return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B2NbOqpL0MF7","colab_type":"code","colab":{}},"source":["model = build_model(\n","  vocab_size = encoder.vocab_size,\n","  embedding_dim=embedding_dim,\n","  rnn_units=rnn_units,\n","  batch_size=BATCH_SIZE)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-ZEhS801CZnF","colab_type":"code","outputId":"4d419d03-f182-4b05-f01a-5b8cd5d6e119","executionInfo":{"status":"ok","timestamp":1572914967806,"user_tz":360,"elapsed":332,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["encoder.vocab_size"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8185"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"ASN8KOa604Dq","colab_type":"code","outputId":"8b306bc6-edaf-4830-deb5-dd3439ef9bb2","executionInfo":{"status":"ok","timestamp":1572914917967,"user_tz":360,"elapsed":337,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["model.summary()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (32, None, 256)           2095360   \n","_________________________________________________________________\n","gru_2 (GRU)                  (32, None, 1024)          3938304   \n","_________________________________________________________________\n","dense_2 (Dense)              (32, None, 8185)          8389625   \n","=================================================================\n","Total params: 14,423,289\n","Trainable params: 14,423,289\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sRI776ZcH3Tf"},"source":["Compile the Keras model to configure the training process:"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kj2xei41YZjC","colab":{}},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=tf.keras.optimizers.Adam(1e-4),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"zIwH3nto596k"},"source":["## Train the model"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hw86wWS4YgR2","colab":{}},"source":["history = model.fit(train_dataset, epochs=10,\n","                    validation_data=test_dataset, \n","                    validation_steps=30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"BaNbXi43YgUT","colab":{}},"source":["test_loss, test_acc = model.evaluate(test_dataset)\n","\n","print('Test Loss: {}'.format(test_loss))\n","print('Test Accuracy: {}'.format(test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DwSE_386uhxD"},"source":["The above model does not mask the padding applied to the sequences. This can lead to skew if trained on padded sequences and test on un-padded sequences. Ideally you would [use masking](../../guide/keras/masking_and_padding) to avoid this, but as you can see below it only have a small effect on the output.\n","\n","If the prediction is >= 0.5, it is positive else it is negative."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8w0dseJMiEUh","colab":{}},"source":["def pad_to_size(vec, size):\n","  zeros = [0] * (size - len(vec))\n","  vec.extend(zeros)\n","  return vec"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Y-E4cgkIvmVu","colab":{}},"source":["def sample_predict(sentence, pad):\n","  encoded_sample_pred_text = encoder.encode(sample_pred_text)\n","\n","  if pad:\n","    encoded_sample_pred_text = pad_to_size(encoded_sample_pred_text, 64)\n","  encoded_sample_pred_text = tf.cast(encoded_sample_pred_text, tf.float32)\n","  predictions = model.predict(tf.expand_dims(encoded_sample_pred_text, 0))\n","\n","  return (predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"O41gw3KfWHus","colab":{}},"source":["# predict on a sample text without padding.\n","\n","sample_pred_text = ('The movie was cool. The animation and the graphics '\n","                    'were out of this world. I would recommend this movie.')\n","predictions = sample_predict(sample_pred_text, pad=False)\n","print (predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"kFh4xLARucTy","colab":{}},"source":["# predict on a sample text with padding\n","\n","sample_pred_text = ('The movie was cool. The animation and the graphics '\n","                    'were out of this world. I would recommend this movie.')\n","predictions = sample_predict(sample_pred_text, pad=True)\n","print (predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZfIVoxiNmKBF","colab":{}},"source":["plot_graphs(history, 'accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"IUzgkqnhmKD2","colab":{}},"source":["plot_graphs(history, 'loss')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7g1evcaRpTKm"},"source":["## Stack two or more LSTM layers\n","\n","Keras recurrent layers have two available modes that are controlled by the `return_sequences` constructor argument:\n","\n","* Return either the full sequences of successive outputs for each timestep (a 3D tensor of shape `(batch_size, timesteps, output_features)`).\n","* Return only the last output for each input sequence (a 2D tensor of shape (batch_size, output_features))."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jo1jjO3vn0jo","colab":{}},"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(encoder.vocab_size, 64),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,  return_sequences=True)),\n","    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hEPV5jVGp-is","colab":{}},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=tf.keras.optimizers.Adam(1e-4),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LeSE-YjdqAeN","colab":{}},"source":["history = model.fit(train_dataset, epochs=10,\n","                    validation_data=test_dataset,\n","                    validation_steps=30)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_LdwilM1qPM3","colab":{}},"source":["test_loss, test_acc = model.evaluate(test_dataset)\n","\n","print('Test Loss: {}'.format(test_loss))\n","print('Test Accuracy: {}'.format(test_acc))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ykUKnAoqbycW","colab":{}},"source":["# predict on a sample text without padding.\n","\n","sample_pred_text = ('The movie was not good. The animation and the graphics '\n","                    'were terrible. I would not recommend this movie.')\n","predictions = sample_predict(sample_pred_text, pad=False)\n","print (predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2RiC-94zvdZO","colab":{}},"source":["# predict on a sample text with padding\n","\n","sample_pred_text = ('The movie was not good. The animation and the graphics '\n","                    'were terrible. I would not recommend this movie.')\n","predictions = sample_predict(sample_pred_text, pad=True)\n","print (predictions)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_YYub0EDtwCu","colab":{}},"source":["plot_graphs(history, 'accuracy')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"DPV3Nn9xtwFM","colab":{}},"source":["plot_graphs(history, 'loss')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"9xvpE3BaGw_V"},"source":["Check out other existing recurrent layers such as [GRU layers](https://www.tensorflow.org/api_docs/python/tf/keras/layers/GRU).\n","\n","If you're interestied in building custom RNNs, see the [Keras RNN Guide](../../guide/keras/rnn.ipynb).\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UQK2Na3Z_aMx","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}