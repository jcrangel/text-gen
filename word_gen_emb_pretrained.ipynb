{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"word_gen_emb_pretrained.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"gnH8yI3795gA","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"ZeDSjThJBP1O","colab_type":"code","outputId":"4d81bae5-8bd7-4159-ed00-cd0f71d1ee8a","executionInfo":{"status":"ok","timestamp":1573626382634,"user_tz":360,"elapsed":16377,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vxPDMDowBbxh","colab_type":"code","outputId":"89791a56-d34e-481e-d6e3-141c9797d22c","executionInfo":{"status":"ok","timestamp":1573626383958,"user_tz":360,"elapsed":426,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%cd gdrive/My\\ Drive/Colab\\ Notebooks/word_generator/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/Colab Notebooks/word_generator\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"InhcUA29HSOS","colab_type":"code","outputId":"99f873cc-f2bb-44b5-8b73-85733b6e1cb4","executionInfo":{"status":"ok","timestamp":1573626622729,"user_tz":360,"elapsed":1685,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["!git add fables_aesop.txt kids_stories.txt word_gen_MLM.ipynb word_gen_emb_pretrained.ipynb"],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: not a git repository (or any of the parent directories): .git\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"My4_4gv2Hvyc","colab_type":"text"},"source":["## Process text"]},{"cell_type":"code","metadata":{"id":"hMtHzsmsVxzV","colab_type":"code","colab":{}},"source":["import string\n","\n","# load doc into memory\n","def load_doc(filename):\n","\t# open the file as read only\n","\tfile = open(filename, 'r')\n","\t# read all text\n","\ttext = file.read()\n","\t# close the file\n","\tfile.close()\n","\treturn text\n","\n","# turn a doc into clean tokens\n","def clean_doc(doc):\n","\t# replace '--' with a space ' '\n","\tdoc = doc.replace('--', ' ')\n","\t# split into tokens by white space\n","\ttokens = doc.split()\n","\t# remove punctuation from each token\n","\ttable = str.maketrans('', '', string.punctuation)\n","\ttokens = [w.translate(table) for w in tokens]\n","\t# remove remaining tokens that are not alphabetic\n","\ttokens = [word for word in tokens if word.isalpha()]\n","\t# make lower case\n","\ttokens = [word.lower() for word in tokens]\n","\treturn tokens\n","\n","# save tokens to file, one dialog per line\n","def save_doc(lines, filename):\n","\tdata = '\\n'.join(lines)\n","\tfile = open(filename, 'w')\n","\tfile.write(data)\n","\tfile.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bbtBVnb0Biww","colab_type":"code","outputId":"12636f02-6828-4894-cd70-8109c0a8ad96","executionInfo":{"status":"ok","timestamp":1573625913034,"user_tz":360,"elapsed":1443,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":237}},"source":["\n","# load document\n","in_filename = 'fables_aesop.txt'\n","doc = load_doc(in_filename)\n","print(doc[:200])\n","\n","# clean document\n","tokens = clean_doc(doc)\n","print(tokens[:200])\n","print('Total Tokens: %d' % len(tokens))\n","print('Unique Tokens: %d' % len(set(tokens)))\n","\n","# organize into sequences of tokens\n","length = 50 + 1\n","sequences = list()\n","for i in range(length, len(tokens)):\n","\t# select sequence of tokens\n","\tseq = tokens[i-length:i]\n","\t# convert into a line\n","\tline = ' '.join(seq)\n","\t# store\n","\tsequences.append(line)\n","print('Total Sequences: %d' % len(sequences))\n","\n","# save sequences to file\n","out_filename = 'fables_aesop_sequences.txt'\n","save_doc(sequences, out_filename)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["THE WOLF AND THE LAMB\n","\n","\n","ONE day a Wolf and a Lamb happened to come at the same time to drink\n","from a brook that ran down the side of the mountain.\n","\n","The Wolf wished very much to eat the Lamb, but meetin\n","['the', 'wolf', 'and', 'the', 'lamb', 'one', 'day', 'a', 'wolf', 'and', 'a', 'lamb', 'happened', 'to', 'come', 'at', 'the', 'same', 'time', 'to', 'drink', 'from', 'a', 'brook', 'that', 'ran', 'down', 'the', 'side', 'of', 'the', 'mountain', 'the', 'wolf', 'wished', 'very', 'much', 'to', 'eat', 'the', 'lamb', 'but', 'meeting', 'her', 'as', 'he', 'did', 'face', 'to', 'face', 'he', 'thought', 'he', 'must', 'find', 'some', 'excuse', 'for', 'doing', 'so', 'so', 'he', 'began', 'by', 'trying', 'to', 'pick', 'a', 'quarrel', 'and', 'said', 'angrily', 'dare', 'you', 'come', 'to', 'my', 'brook', 'and', 'muddy', 'the', 'water', 'so', 'that', 'i', 'cannot', 'drink', 'it', 'what', 'do', 'you', 'the', 'lamb', 'very', 'much', 'alarmed', 'said', 'gently', 'do', 'not', 'see', 'how', 'it', 'can', 'be', 'that', 'i', 'have', 'spoiled', 'the', 'water', 'you', 'stand', 'higher', 'up', 'the', 'stream', 'and', 'the', 'water', 'runs', 'from', 'you', 'to', 'me', 'not', 'from', 'me', 'to', 'that', 'as', 'it', 'said', 'the', 'wolf', 'with', 'a', 'snarl', 'are', 'a', 'rascal', 'all', 'the', 'same', 'for', 'i', 'have', 'heard', 'that', 'last', 'year', 'you', 'said', 'bad', 'things', 'of', 'me', 'behind', 'my', 'mr', 'cried', 'the', 'poor', 'lamb', 'could', 'not', 'be', 'for', 'a', 'year', 'ago', 'i', 'was', 'not', 'born', 'i', 'am', 'only', 'six', 'months', 'finding', 'it', 'of', 'no', 'use', 'to', 'argue', 'any', 'more', 'the', 'wolf', 'began', 'to', 'snarl', 'and', 'show', 'his', 'teeth', 'coming', 'closer']\n","Total Tokens: 88800\n","Unique Tokens: 7824\n","Total Sequences: 88749\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Gft2Tt9MHzT5","colab_type":"text"},"source":["## get training data"]},{"cell_type":"markdown","metadata":{"id":"Dng-28iFkKWo","colab_type":"text"},"source":["Read the vector from glove file"]},{"cell_type":"code","metadata":{"id":"khNS6O1_Weo5","colab_type":"code","colab":{}},"source":["import numpy as np\n","\n","def read_glove_vecs(glove_file):\n","    with open(glove_file, 'r') as f:\n","        words = set()\n","        word_to_vec_map = {}\n","        for line in f:\n","            line = line.strip().split()\n","            curr_word = line[0]\n","            words.add(curr_word)\n","            word_to_vec_map[curr_word] = np.array(line[1:], dtype=np.float64)\n","        \n","        i = 1\n","        words_to_index = {}\n","        index_to_words = {}\n","        for w in sorted(words):\n","            words_to_index[w] = i\n","            index_to_words[i] = w\n","            i = i + 1\n","\n","    return words_to_index, index_to_words, word_to_vec_map"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mbLhpb1OkJoF","colab_type":"code","colab":{}},"source":["word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('glove.6B.50d.txt')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"b2ly46zKj84g","colab_type":"code","colab":{}},"source":["# GRADED FUNCTION: sentences_to_indices\n","\n","def sentences_to_indices(X, word_to_index, index_to_word, word_to_vec_map, max_len):\n","    \"\"\"\n","    Converts an array of sentences (strings) into an array of indices corresponding to words in the sentences.\n","    The output shape should be such that it can be given to `Embedding()` (described in Figure 4). \n","    \n","    Arguments:\n","    X -- array of sentences (strings), of shape (m, 1)\n","    word_to_index -- a dictionary containing the each word mapped to its index\n","    max_len -- maximum number of words in a sentence. You can assume every sentence in X is no longer than this. \n","    \n","    Returns:\n","    X_indices -- array of indices corresponding to words in the sentences from X, of shape (m, max_len)\n","    \"\"\"\n","    \n","    m = X.shape[0]                                   # number of training examples\n","    vec_len = word_to_vec_map['baseball'].shape[0]\n","    # import pdb; pdb.set_trace()\n","    ### START CODE HERE ###\n","    # Initialize X_indices as a numpy matrix of zeros and the correct shape (≈ 1 line)\n","    X_indices = np.zeros( shape = (m, max_len))\n","    \n","    for i in range(m):                               # loop over training examples\n","        \n","        # Convert the ith training sentence in lower case and split is into words. You should get a list of words.\n","        # sentence_words = list(map(lambda x : x.lower() , X[i].split(\" \")))\n","        sentence_words = [i.lower() for i in X[i].split()]\n","        # Initialize j to 0\n","        j = 0\n","        \n","        # Loop over the words of sentence_words\n","        for w in sentence_words:\n","            # Set the (i,j)th entry of X_indices to the index of the correct word.\n","            try:\n","              X_indices[i, j] = word_to_index[w]\n","            except KeyError:\n","              print(w + \" doesnt have index, new entry created\")\n","              \n","              vocab_size = len(word_to_index) + 1\n","              word_to_index[w] = vocab_size\n","              X_indices[i, j] = vocab_size\n","              word_to_vec_map[w] = np.random.rand(vec_len)\n","              index_to_word[vocab_size] = w \n","              continue\n","            # Increment j to j + 1\n","            j += 1\n","    ### END CODE HERE ###\n","    # pdb.set_trace()\n","    return X_indices"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_K3kkn1J0nfj","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"D8mSuOZOkTRt","colab_type":"code","outputId":"3d176c70-77d6-4087-ef86-1a468d34e7de","executionInfo":{"status":"ok","timestamp":1573625948468,"user_tz":360,"elapsed":291,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":90}},"source":["X1 = np.array([\"funny lol\", \"lets play baseball\", \"food is ready for you\"])\n","X1_indices = sentences_to_indices(X1,word_to_index, index_to_word, word_to_vec_map, max_len = 5)\n","print(\"X1 =\", X1)\n","print(\"X1_indices =\", X1_indices)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["X1 = ['funny lol' 'lets play baseball' 'food is ready for you']\n","X1_indices = [[155345. 225122.      0.      0.      0.]\n"," [220930. 286375.  69714.      0.      0.]\n"," [151204. 192973. 302254. 151349. 394475.]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oslLS2XUBssR","colab_type":"code","outputId":"a606c39e-78f0-4438-8f5d-fc4f3dc0640d","executionInfo":{"status":"ok","timestamp":1573625951512,"user_tz":360,"elapsed":1827,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":65}},"source":["from numpy import array\n","from pickle import dump\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import LSTM\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras.layers import Bidirectional \n"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ZlR6QZXVkcot","colab_type":"code","colab":{}},"source":["# load\n","in_filename = 'fables_aesop_sequences.txt'\n","doc = load_doc(in_filename)\n","lines = doc.split('\\n')\n","lines = np.array(lines)\n","length = 50 + 1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_j7VoWn70v3W","colab_type":"code","outputId":"3740673a-9b0a-4a56-9779-02280e1f8431","executionInfo":{"status":"ok","timestamp":1573625956339,"user_tz":360,"elapsed":333,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":128}},"source":["print(lines[:5])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['the wolf and the lamb one day a wolf and a lamb happened to come at the same time to drink from a brook that ran down the side of the mountain the wolf wished very much to eat the lamb but meeting her as he did face to face he'\n"," 'wolf and the lamb one day a wolf and a lamb happened to come at the same time to drink from a brook that ran down the side of the mountain the wolf wished very much to eat the lamb but meeting her as he did face to face he thought'\n"," 'and the lamb one day a wolf and a lamb happened to come at the same time to drink from a brook that ran down the side of the mountain the wolf wished very much to eat the lamb but meeting her as he did face to face he thought he'\n"," 'the lamb one day a wolf and a lamb happened to come at the same time to drink from a brook that ran down the side of the mountain the wolf wished very much to eat the lamb but meeting her as he did face to face he thought he must'\n"," 'lamb one day a wolf and a lamb happened to come at the same time to drink from a brook that ran down the side of the mountain the wolf wished very much to eat the lamb but meeting her as he did face to face he thought he must find']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1R0N9cTA7uUR","colab_type":"code","outputId":"c99cea15-e0dc-44ae-bda4-435155bad394","executionInfo":{"status":"ok","timestamp":1573625959806,"user_tz":360,"elapsed":2301,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# integer encode sequences of words\n","#okenizer = Tokenizer()\n","#tokenizer.fit_on_texts(lines)\n","\n","#array([   15,     1,   306, 10270,    28,     7,   363,   225,  4604,....])\n","sequences = sentences_to_indices(lines,word_to_index, index_to_word, word_to_vec_map, max_len = length)\n","# vocabulary size\n","vocab_size = len(word_to_index) + 1  \n","X, y = sequences[:,:-1], sequences[:,-1]\n","#y = to_categorical(y, num_classes=vocab_size) eats all memory use sparse_categorical_crossentropy\n","seq_length = X.shape[1]"],"execution_count":12,"outputs":[{"output_type":"stream","text":["famishing doesnt have index, new entry created\n","storkking doesnt have index, new entry created\n","grayear doesnt have index, new entry created\n","whitewhisker doesnt have index, new entry created\n","gayly doesnt have index, new entry created\n","unsuspicious doesnt have index, new entry created\n","capered doesnt have index, new entry created\n","selfimportance doesnt have index, new entry created\n","dainties doesnt have index, new entry created\n","manyfeathered doesnt have index, new entry created\n","oneeyed doesnt have index, new entry created\n","repine doesnt have index, new entry created\n","filberts doesnt have index, new entry created\n","illmannered doesnt have index, new entry created\n","cowhides doesnt have index, new entry created\n","fairtime doesnt have index, new entry created\n","wellproved doesnt have index, new entry created\n","dinnerless doesnt have index, new entry created\n","miry doesnt have index, new entry created\n","selfinterest doesnt have index, new entry created\n","evildisposed doesnt have index, new entry created\n","faultfinding doesnt have index, new entry created\n","rushlight doesnt have index, new entry created\n","relighted doesnt have index, new entry created\n","wisping doesnt have index, new entry created\n","starveling doesnt have index, new entry created\n","puffedout doesnt have index, new entry created\n","scapegrace doesnt have index, new entry created\n","importunity doesnt have index, new entry created\n","rodiland doesnt have index, new entry created\n","rateater doesnt have index, new entry created\n","unkilled doesnt have index, new entry created\n","moujiks doesnt have index, new entry created\n","æsop doesnt have index, new entry created\n","bethought doesnt have index, new entry created\n","affrighted doesnt have index, new entry created\n","goodnatured doesnt have index, new entry created\n","fourfooted doesnt have index, new entry created\n","mouselike doesnt have index, new entry created\n","illmatched doesnt have index, new entry created\n","dotingly doesnt have index, new entry created\n","surprized doesnt have index, new entry created\n","overanxiety doesnt have index, new entry created\n","bantling doesnt have index, new entry created\n","wellgrown doesnt have index, new entry created\n","shews doesnt have index, new entry created\n","schoolfellows doesnt have index, new entry created\n","meanspirited doesnt have index, new entry created\n","controul doesnt have index, new entry created\n","tutorage doesnt have index, new entry created\n","stiled doesnt have index, new entry created\n","behoves doesnt have index, new entry created\n","jocosely doesnt have index, new entry created\n","intreats doesnt have index, new entry created\n","stopt doesnt have index, new entry created\n","recal doesnt have index, new entry created\n","findeth doesnt have index, new entry created\n","gaminghouses doesnt have index, new entry created\n","sharping doesnt have index, new entry created\n","mistakingly doesnt have index, new entry created\n","irrecoverably doesnt have index, new entry created\n","unwearied doesnt have index, new entry created\n","wellorganized doesnt have index, new entry created\n","œconomy doesnt have index, new entry created\n","fragrancy doesnt have index, new entry created\n","cloaths doesnt have index, new entry created\n","shewed doesnt have index, new entry created\n","illjudged doesnt have index, new entry created\n","shewing doesnt have index, new entry created\n","derogates doesnt have index, new entry created\n","sharpers doesnt have index, new entry created\n","befal doesnt have index, new entry created\n","sheepbiter doesnt have index, new entry created\n","expostulate doesnt have index, new entry created\n","ungratitude doesnt have index, new entry created\n","infelicity doesnt have index, new entry created\n","needeth doesnt have index, new entry created\n","doubletongued doesnt have index, new entry created\n","welldisposed doesnt have index, new entry created\n","gobetweens doesnt have index, new entry created\n","clapt doesnt have index, new entry created\n","dunghill doesnt have index, new entry created\n","allurements doesnt have index, new entry created\n","dropt doesnt have index, new entry created\n","designedly doesnt have index, new entry created\n","selfapprobation doesnt have index, new entry created\n","vizor doesnt have index, new entry created\n","undrest doesnt have index, new entry created\n","embued doesnt have index, new entry created\n","unenvied doesnt have index, new entry created\n","boaster doesnt have index, new entry created\n","expence doesnt have index, new entry created\n","asseverations doesnt have index, new entry created\n","selfconceited doesnt have index, new entry created\n","betimes doesnt have index, new entry created\n","illwill doesnt have index, new entry created\n","fiendlike doesnt have index, new entry created\n","irreconcileable doesnt have index, new entry created\n","unfrequently doesnt have index, new entry created\n","visitants doesnt have index, new entry created\n","officiousness doesnt have index, new entry created\n","pismires doesnt have index, new entry created\n","illnatured doesnt have index, new entry created\n","burthens doesnt have index, new entry created\n","shewn doesnt have index, new entry created\n","aftertimes doesnt have index, new entry created\n","asperse doesnt have index, new entry created\n","periwig doesnt have index, new entry created\n","captious doesnt have index, new entry created\n","disquietude doesnt have index, new entry created\n","selfinterested doesnt have index, new entry created\n","bespatter doesnt have index, new entry created\n","sulkily doesnt have index, new entry created\n","slightingly doesnt have index, new entry created\n","acquirements doesnt have index, new entry created\n","illfortune doesnt have index, new entry created\n","overselfish doesnt have index, new entry created\n","narrowminded doesnt have index, new entry created\n","engross doesnt have index, new entry created\n","apprized doesnt have index, new entry created\n","undeceives doesnt have index, new entry created\n","twelvemonth doesnt have index, new entry created\n","roguery doesnt have index, new entry created\n","illgoverned doesnt have index, new entry created\n","expiates doesnt have index, new entry created\n","burialplace doesnt have index, new entry created\n","insensibly doesnt have index, new entry created\n","stupifies doesnt have index, new entry created\n","oftener doesnt have index, new entry created\n","espied doesnt have index, new entry created\n","unprovided doesnt have index, new entry created\n","tinctured doesnt have index, new entry created\n","forebore doesnt have index, new entry created\n","unblest doesnt have index, new entry created\n","intreated doesnt have index, new entry created\n","farrowed doesnt have index, new entry created\n","obtrudes doesnt have index, new entry created\n","panicstruck doesnt have index, new entry created\n","pisistratus doesnt have index, new entry created\n","bunghole doesnt have index, new entry created\n","phædrus doesnt have index, new entry created\n","burthensome doesnt have index, new entry created\n","importunities doesnt have index, new entry created\n","repinings doesnt have index, new entry created\n","rufflings doesnt have index, new entry created\n","wouldst doesnt have index, new entry created\n","mischiefs doesnt have index, new entry created\n","obtrude doesnt have index, new entry created\n","goodfornothing doesnt have index, new entry created\n","distempers doesnt have index, new entry created\n","lanthorn doesnt have index, new entry created\n","phiz doesnt have index, new entry created\n","oculists doesnt have index, new entry created\n","dogmatical doesnt have index, new entry created\n","perverseness doesnt have index, new entry created\n","bloodo doesnt have index, new entry created\n","longeared doesnt have index, new entry created\n","fourlegged doesnt have index, new entry created\n","halfstarved doesnt have index, new entry created\n","doubledealing doesnt have index, new entry created\n","coxcombs doesnt have index, new entry created\n","drawingroom doesnt have index, new entry created\n","defiances doesnt have index, new entry created\n","dastard doesnt have index, new entry created\n","littleness doesnt have index, new entry created\n","weakminded doesnt have index, new entry created\n","misenus doesnt have index, new entry created\n","officiously doesnt have index, new entry created\n","complaisance doesnt have index, new entry created\n","broils doesnt have index, new entry created\n","wellmeaning doesnt have index, new entry created\n","undiscerning doesnt have index, new entry created\n","wornout doesnt have index, new entry created\n","injuriously doesnt have index, new entry created\n","lyingin doesnt have index, new entry created\n","befool doesnt have index, new entry created\n","pettish doesnt have index, new entry created\n","sirrah doesnt have index, new entry created\n","criminate doesnt have index, new entry created\n","fellowsubjects doesnt have index, new entry created\n","selfconceit doesnt have index, new entry created\n","inconsiderately doesnt have index, new entry created\n","revilings doesnt have index, new entry created\n","familiarities doesnt have index, new entry created\n","agoing doesnt have index, new entry created\n","thieftaker doesnt have index, new entry created\n","raillery doesnt have index, new entry created\n","fullyprepared doesnt have index, new entry created\n","supplicate doesnt have index, new entry created\n","tyrannise doesnt have index, new entry created\n","slabbered doesnt have index, new entry created\n","ingenuously doesnt have index, new entry created\n","hissings doesnt have index, new entry created\n","counterplot doesnt have index, new entry created\n","blackamoor doesnt have index, new entry created\n","illconcerted doesnt have index, new entry created\n","unheeding doesnt have index, new entry created\n","woful doesnt have index, new entry created\n","prithee doesnt have index, new entry created\n","enterprizes doesnt have index, new entry created\n","selfsufficient doesnt have index, new entry created\n","surfeited doesnt have index, new entry created\n","screamings doesnt have index, new entry created\n","unmeaning doesnt have index, new entry created\n","inveigling doesnt have index, new entry created\n","allwise doesnt have index, new entry created\n","misapply doesnt have index, new entry created\n","oxstall doesnt have index, new entry created\n","mastereye doesnt have index, new entry created\n","ringdove doesnt have index, new entry created\n","ashooting doesnt have index, new entry created\n","desponding doesnt have index, new entry created\n","miserableness doesnt have index, new entry created\n","scurvily doesnt have index, new entry created\n","suppliant doesnt have index, new entry created\n","fellowcreatures doesnt have index, new entry created\n","goodnature doesnt have index, new entry created\n","lenity doesnt have index, new entry created\n","brainracking doesnt have index, new entry created\n","unpitied doesnt have index, new entry created\n","impieties doesnt have index, new entry created\n","deeplaid doesnt have index, new entry created\n","froward doesnt have index, new entry created\n","supperless doesnt have index, new entry created\n","apologue doesnt have index, new entry created\n","calumniators doesnt have index, new entry created\n","sots doesnt have index, new entry created\n","precedency doesnt have index, new entry created\n","partaker doesnt have index, new entry created\n","beggarly doesnt have index, new entry created\n","wellstored doesnt have index, new entry created\n","illgotten doesnt have index, new entry created\n","insatiate doesnt have index, new entry created\n","menenius doesnt have index, new entry created\n","illluck doesnt have index, new entry created\n","dovehouse doesnt have index, new entry created\n","chuse doesnt have index, new entry created\n","scrupled doesnt have index, new entry created\n","wellbred doesnt have index, new entry created\n","shamefacedness doesnt have index, new entry created\n","wellfed doesnt have index, new entry created\n","changeableness doesnt have index, new entry created\n","downfal doesnt have index, new entry created\n","unfeelingly doesnt have index, new entry created\n","purseproud doesnt have index, new entry created\n","ingrafted doesnt have index, new entry created\n","enfeebles doesnt have index, new entry created\n","affronting doesnt have index, new entry created\n","illlanguage doesnt have index, new entry created\n","placeman doesnt have index, new entry created\n","playfellow doesnt have index, new entry created\n","parings doesnt have index, new entry created\n","diningroom doesnt have index, new entry created\n","townlife doesnt have index, new entry created\n","pellmell doesnt have index, new entry created\n","selfpreservation doesnt have index, new entry created\n","soever doesnt have index, new entry created\n","loobies doesnt have index, new entry created\n","humouring doesnt have index, new entry created\n","mischance doesnt have index, new entry created\n","deservest doesnt have index, new entry created\n","overflowings doesnt have index, new entry created\n","inclemency doesnt have index, new entry created\n","dissembler doesnt have index, new entry created\n","jackalls doesnt have index, new entry created\n","warsaddle doesnt have index, new entry created\n","inadvertency doesnt have index, new entry created\n","hidingplace doesnt have index, new entry created\n","knavish doesnt have index, new entry created\n","equivocates doesnt have index, new entry created\n","inviolably doesnt have index, new entry created\n","unremitted doesnt have index, new entry created\n","unbend doesnt have index, new entry created\n","slily doesnt have index, new entry created\n","envenomed doesnt have index, new entry created\n","dissentions doesnt have index, new entry created\n","illusage doesnt have index, new entry created\n","ungirded doesnt have index, new entry created\n","packsaddle doesnt have index, new entry created\n","fellowservant doesnt have index, new entry created\n","newsown doesnt have index, new entry created\n","poltroon doesnt have index, new entry created\n","gallanted doesnt have index, new entry created\n","equinamity doesnt have index, new entry created\n","fullbodied doesnt have index, new entry created\n","uneasinesses doesnt have index, new entry created\n","tuftcovered doesnt have index, new entry created\n","peculation doesnt have index, new entry created\n","intrusted doesnt have index, new entry created\n","knawed doesnt have index, new entry created\n","depicture doesnt have index, new entry created\n","prepossess doesnt have index, new entry created\n","viands doesnt have index, new entry created\n","provocatives doesnt have index, new entry created\n","gamesome doesnt have index, new entry created\n","titbit doesnt have index, new entry created\n","likings doesnt have index, new entry created\n","overgrasping doesnt have index, new entry created\n","fomenter doesnt have index, new entry created\n","twoedged doesnt have index, new entry created\n","widespreading doesnt have index, new entry created\n","vollies doesnt have index, new entry created\n","hardheartedness doesnt have index, new entry created\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KIg0S5kn70F4","colab_type":"code","outputId":"9ec72dab-e912-4af7-fb6a-a210e24a9a38","executionInfo":{"status":"ok","timestamp":1573625961822,"user_tz":360,"elapsed":380,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["len(word_to_vec_map)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["400303"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"lBNStpd5m2gg","colab_type":"code","outputId":"871c6e50-ed2e-46b0-8747-3a000fc70427","executionInfo":{"status":"ok","timestamp":1573625963024,"user_tz":360,"elapsed":296,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["word_to_index['mermaid']"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["241527"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"z1P0-UUtCle8","colab_type":"text"},"source":["## Pretrain embedding layer"]},{"cell_type":"markdown","metadata":{"id":"c8AXXgK-oGuN","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"2CQCvNb3CIVN","colab_type":"code","colab":{}},"source":["\n","def pretrained_embedding_layer(word_to_vec_map, word_to_index, trainable = False):\n","    \"\"\"\n","    Creates a Keras Embedding() layer and loads in pre-trained GloVe 50-dimensional vectors.\n","    \n","    Arguments:\n","    word_to_vec_map -- dictionary mapping words to their GloVe vector representation.\n","    word_to_index -- dictionary mapping from words to their indices in the vocabulary (400,001 words)\n","\n","    Returns:\n","    embedding_layer -- pretrained layer Keras instance\n","    \"\"\"\n","    \n","    vocab_len = len(word_to_index) + 1                  # adding 1 to fit Keras embedding (requirement)\n","    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n","    \n","    ### START CODE HERE ###\n","    # Initialize the embedding matrix as a numpy array of zeros of shape (vocab_len, dimensions of word vectors = emb_dim)\n","    emb_matrix = np.zeros(shape=(vocab_len,emb_dim))\n","    \n","    # Set each row \"index\" of the embedding matrix to be the word vector representation of the \"index\"th word of the vocabulary\n","    for word, index in word_to_index.items():\n","        emb_matrix[index, :] = word_to_vec_map[word]\n","\n","    # Define Keras embedding layer with the correct output/input sizes, make it non-trainable. Use Embedding(...). Make sure to set trainable=False. \n","    embedding_layer = Embedding(vocab_len,emb_dim,trainable=trainable)\n","    \n","    ### END CODE HERE ###\n","\n","    # Build the embedding layer, it is required before setting the weights of the embedding layer. Do not modify the \"None\".\n","    embedding_layer.build((None,))\n","    \n","    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n","    embedding_layer.set_weights([emb_matrix])\n","    \n","    return embedding_layer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBHNrUuVX6Jn","colab_type":"code","outputId":"bf558089-23ac-4509-a234-8bae99c3eb03","executionInfo":{"status":"error","timestamp":1573611323821,"user_tz":360,"elapsed":2646,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}},"colab":{"base_uri":"https://localhost:8080/","height":184}},"source":["embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n","print(\"weights[0][1][3] =\", embedding_layer.get_weights()[0][1][3])"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-5a61855c3e01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained_embedding_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_to_vec_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights[0][1][3] =\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pretrained_embedding_layer' is not defined"]}]},{"cell_type":"code","metadata":{"id":"PHvueG3nmsPp","colab_type":"code","colab":{}},"source":["from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.optimizers import Adagrad\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.callbacks import ModelCheckpoint"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JZNlbHkVYlAK","colab_type":"code","colab":{}},"source":["\n","# define model\n","model = Sequential()\n","# in : (batch, input_lengh) , [12,3,2,3,4,5,12,..., input_lentgh]\n","\n","model.add(pretrained_embedding_layer(word_to_vec_map,word_to_index,trainable = False))\n","model.add(Bidirectional(LSTM(100, return_sequences=True)) )\n","model.add(Bidirectional(LSTM(100)) )\n","model.add(Dense(100, activation='relu'))\n","model.add(Dense(vocab_size, activation='softmax'))\n","print(model.summary())\n","# compile model\n","opt = Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n","# opt = SGD(learning_rate=0.001, momentum=0.0)\n","# opt = Adagrad(learning_rate=0.001)\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\n","filepath=\"weights-improvement.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]\n","# fit model\n","model.fit(X, y, batch_size=128, epochs=100, callbacks=callbacks_list)\n","\n","# save the model to file\n","model.save('model_embpre.h5')\n","# save the tokenizer\n","dump(tokenizer, open('tokenizer.pkl', 'wb'))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MkRxd-h48rKn","colab_type":"text"},"source":["Reload and continue training"]},{"cell_type":"code","metadata":{"id":"BmbPOszOrQFR","colab_type":"code","outputId":"6dd47d52-c2cb-495c-f770-c4100c596118","colab":{"base_uri":"https://localhost:8080/","height":419}},"source":["from tensorflow.keras.models import load_model\n","\n","filepath=\"weights-improvement.hdf5\"\n","model = load_model(filepath)\n","checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [checkpoint]\n","# fit model\n","model.fit(X, y, batch_size=128, epochs=100, callbacks=callbacks_list)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Train on 88749 samples\n","Epoch 1/100\n","54272/88749 [=================>............] - ETA: 1:32 - loss: 3.4743 - acc: 0.2600"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z-xrWoh68vf6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"7846b056-f38d-4637-e31d-d069130a6bbe","executionInfo":{"status":"ok","timestamp":1573626349858,"user_tz":360,"elapsed":1763,"user":{"displayName":"Julio C. Rangel","photoUrl":"","userId":"14108141314989218174"}}},"source":[""],"execution_count":1,"outputs":[{"output_type":"stream","text":["fatal: not a git repository (or any of the parent directories): .git\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lQJfUfMpcHVN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}